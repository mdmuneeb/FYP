{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# CONFIG\n",
    "# =============================\n",
    "MODEL_PATH = \"runs/segment/rice_yolo_runs/yolov8m_seg/weights/best.pt\"\n",
    "IMAGE_DIR  = \"rice_dataset/train/images\"   # change to valid/test if needed\n",
    "SAVE_DIR   = \"rice_crops\"\n",
    "IMG_SIZE   = 224   # for CNNs later\n",
    "\n",
    "# =============================\n",
    "# LOAD MODEL\n",
    "# =============================\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# =============================\n",
    "# MASK CROP FUNCTION\n",
    "# =============================\n",
    "def crop_from_mask(img, mask):\n",
    "    \"\"\"\n",
    "    Extract tight crop using segmentation mask\n",
    "    \"\"\"\n",
    "    mask = mask.astype(np.uint8)\n",
    "\n",
    "    # get bounding rect around mask\n",
    "    x, y, w, h = cv2.boundingRect(mask)\n",
    "\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    crop_mask = mask[y:y+h, x:x+w]\n",
    "\n",
    "    # remove background\n",
    "    crop_img = cv2.bitwise_and(crop_img, crop_img, mask=crop_mask)\n",
    "\n",
    "    return crop_img\n",
    "\n",
    "\n",
    "# =============================\n",
    "# PREDICT + SAVE CROPS\n",
    "# =============================\n",
    "results = model.predict(\n",
    "    source=IMAGE_DIR,\n",
    "    stream=True,     # important for memory\n",
    "    conf=0.25,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Extracting grains...\")\n",
    "\n",
    "for r in tqdm(results):\n",
    "\n",
    "    img = r.orig_img\n",
    "    image_name = os.path.splitext(os.path.basename(r.path))[0]\n",
    "\n",
    "    if r.masks is None:\n",
    "        continue\n",
    "\n",
    "    masks = r.masks.data.cpu().numpy()\n",
    "    classes = r.boxes.cls.cpu().numpy()\n",
    "\n",
    "    for i, (mask, cls_id) in enumerate(zip(masks, classes)):\n",
    "\n",
    "        mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
    "        mask = (mask > 0.5).astype(np.uint8)\n",
    "\n",
    "        crop = crop_from_mask(img, mask)\n",
    "\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        # resize for CNN\n",
    "        crop = cv2.resize(crop, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        class_name = model.names[int(cls_id)]\n",
    "\n",
    "        class_folder = os.path.join(SAVE_DIR, class_name)\n",
    "        os.makedirs(class_folder, exist_ok=True)\n",
    "\n",
    "        save_path = os.path.join(class_folder, f\"{image_name}_{i}.jpg\")\n",
    "\n",
    "        cv2.imwrite(save_path, crop)\n",
    "\n",
    "\n",
    "print(\"âœ… Done! Crops saved to:\", SAVE_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
